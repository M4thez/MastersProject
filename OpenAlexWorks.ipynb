{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c213ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyalex import config, Works, Authors, Sources, Institutions, Topics, Publishers, Funders\n",
    "import helpers\n",
    "import time\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import pyarrow # engine for parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f698cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email Configuration for the polite pool\n",
    "config.email = \"bm57596@zut.edu.pl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67655c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for retrying requests\n",
    "config.max_retries = 3\n",
    "config.retry_backoff_factor = 0.5  # delay between two retries\n",
    "config.retry_https_codes = [429, 500, 503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42edc02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PL_ZUT': '0596m7f19', 'BG_BFU': '02ek1bx64', 'GR_UOP': '017wvtq80', 'HR_UNIDU': '05yptqp13', 'SL_EMUNI': '03761pf32', 'IT_UNISS': '01bnjbv91', 'FR_UAG': '02ryfmr77', 'PT_UAC': '04276xd64', 'ES_UIB': '03e10x626', 'FR_ULHN': '05v509s40', 'FO_UF': '05mwmd090', 'DE_HOCHSTRALSUND': '04g99jx54', 'FI_AUAS': '05mknbx32'}\n"
     ]
    }
   ],
   "source": [
    "universities_ror_url = {\n",
    "    # West Pomeranian University of Technology in Szczecin\n",
    "    'PL_ZUT': 'https://ror.org/0596m7f19',\n",
    "    # Burgas Free University\n",
    "    'BG_BFU': 'https://ror.org/02ek1bx64',\n",
    "    # University of Patras\n",
    "    'GR_UOP': 'https://ror.org/017wvtq80',\n",
    "    # University of Dubrovnik\n",
    "    'HR_UNIDU': 'https://ror.org/05yptqp13',\n",
    "    # University EMUNI\n",
    "    'SL_EMUNI': 'https://ror.org/03761pf32',\n",
    "    # University of Sassari\n",
    "    'IT_UNISS': 'https://ror.org/01bnjbv91',\n",
    "    # University of the Antilles\n",
    "    'FR_UAG': 'https://ror.org/02ryfmr77',\n",
    "    # University of the Azores\n",
    "    'PT_UAC': 'https://ror.org/04276xd64',\n",
    "    # University of the Balearic Islands\n",
    "    'ES_UIB': 'https://ror.org/03e10x626',\n",
    "    # University Le Havre Normandie\n",
    "    'FR_ULHN': 'https://ror.org/05v509s40',\n",
    "    # University of the Faroe Islands\n",
    "    'FO_UF': 'https://ror.org/05mwmd090',\n",
    "    # Stralsund University of Applied Sciences\n",
    "    'DE_HOCHSTRALSUND': 'https://ror.org/04g99jx54',\n",
    "    # Åland University of Applied Sciences\n",
    "    'FI_AUAS': 'https://ror.org/05mknbx32',\n",
    "}\n",
    "\n",
    "# Just ROR IDs stored in universities_ror_id dictionary \n",
    "universities_ror_id = {}\n",
    "for key in universities_ror_url:\n",
    "    universities_ror_id[key] = helpers.extract_id_from_url(universities_ror_url[key])\n",
    "\n",
    "print(universities_ror_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b87e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_papers_by_ror(ror_id, n_max=300):\n",
    "    \"\"\"\n",
    "    Fetches research papers associated with a given Research Organization Registry (ROR) ID from the OpenAlex API.\n",
    "\n",
    "    Args:\n",
    "        ror_id (str): The ROR ID of the institution.\n",
    "        n_max (int, optional): The maximum number of papers to fetch. Defaults to 300. Set to None to fetch all.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains the extracted data of a research paper.\n",
    "              Returns an empty list if an error occurs during fetching.\n",
    "    \"\"\"\n",
    "    all_papers_data = []\n",
    "    processed_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        query = Works().filter(institutions={\"ror\": ror_id})\n",
    "\n",
    "        for work in chain(*query.paginate(per_page=200, n_max=n_max)):\n",
    "            processed_count += 1\n",
    "\n",
    "            if processed_count % 200 == 0:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(\n",
    "                    f\"Processed {processed_count} works... (Time elapsed: {elapsed_time:.2f}s)\")\n",
    "\n",
    "            # if processed_count == 1:\n",
    "            #     print(\"KEYS:\", work.keys())\n",
    "\n",
    "            abstract = work['abstract']\n",
    "            authorships = work.get('authorships', [])\n",
    "            author_names = []\n",
    "            institutions_names = []\n",
    "\n",
    "            for authorship in authorships:\n",
    "                author = authorship.get('author')\n",
    "                institutions = authorship.get('institutions')\n",
    "\n",
    "                # if processed_count == 1:\n",
    "                #     print(\"AUTHORS:\", author)\n",
    "\n",
    "                for inst in institutions:\n",
    "                    name_to_add = None\n",
    "                    if inst and inst.get('display_name'):\n",
    "                        name_to_add = inst['display_name']\n",
    "                    if name_to_add not in institutions_names:\n",
    "                        institutions_names.append(name_to_add)\n",
    "\n",
    "                if author and author.get('display_name'):\n",
    "                    author_names.append(author['display_name'])\n",
    "\n",
    "            all_papers_data.append({\n",
    "                \"openalex_id\": work.get('id'),\n",
    "                \"doi\": work.get('doi'),\n",
    "                \"language\": work.get('language'),\n",
    "                \"type\": work.get('type'),\n",
    "                \"title\": work.get('title'),\n",
    "                \"publication_date\": work.get('publication_date'),\n",
    "                \"primary_location\": work.get('primary_location'),\n",
    "                \"open_access\": work.get('open_access'),\n",
    "                # \"best_oa_location\": work.get('best_oa_location'),\n",
    "                \"institutions\": institutions_names,\n",
    "                \"authors\": author_names,\n",
    "                \"cited_by_count\": work.get('cited_by_count'),\n",
    "                \"fwci\": work.get('fwci'),\n",
    "                \"citation_normalized_percentile\": work.get('citation_normalized_percentile'),\n",
    "                \"is_retracted\": work.get('is_retracted'),\n",
    "                \"is_paratext\": work.get('is_paratext'),\n",
    "                \"abstract\": abstract,\n",
    "                \"primary_topic\": work.get('primary_topic'),\n",
    "                \"topics\": work.get('topics'),\n",
    "                \"keywords\": work.get('keywords'),\n",
    "                \"cited_by_api_url\": work.get('cited_by_api_url'),\n",
    "                \"updated_date\": work.get('updated_date'),\n",
    "                \"created_date\": work.get('created_date'),\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during fetching: {e}\")\n",
    "        print(f\"Processed {processed_count} works before the error.\")\n",
    "        return []\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nFinished fetching.\")\n",
    "    print(f\"Total papers found and processed: {len(all_papers_data)}\")\n",
    "    print(f\"Total time taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return all_papers_data\n",
    "\n",
    "# --- Example Usage ---\n",
    "# ROR for the specific university\n",
    "# ROR_ID = universities_ror_id['PL_ZUT']\n",
    "# print(f\"Fetching works for institution ROR: {ROR_ID}\")\n",
    "\n",
    "# # Fetch papers for the specified ROR ID\n",
    "# example_papers_data = fetch_papers_by_ror(ROR_ID, n_max=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1797c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching works for institution PL_ZUT ROR: 0596m7f19\n",
      "Processed 200 works... (Time elapsed: 6.85s)\n",
      "Processed 400 works... (Time elapsed: 6.87s)\n",
      "Processed 600 works... (Time elapsed: 7.01s)\n",
      "Processed 800 works... (Time elapsed: 7.04s)\n",
      "Processed 1000 works... (Time elapsed: 7.05s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 7.10 seconds\n",
      "Fetching works for institution BG_BFU ROR: 02ek1bx64\n",
      "Processed 200 works... (Time elapsed: 4.64s)\n",
      "Processed 400 works... (Time elapsed: 4.66s)\n",
      "Processed 600 works... (Time elapsed: 4.67s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 642\n",
      "Total time taken: 4.69 seconds\n",
      "Fetching works for institution GR_UOP ROR: 017wvtq80\n",
      "Processed 200 works... (Time elapsed: 8.79s)\n",
      "Processed 400 works... (Time elapsed: 8.80s)\n",
      "Processed 600 works... (Time elapsed: 8.82s)\n",
      "Processed 800 works... (Time elapsed: 8.83s)\n",
      "Processed 1000 works... (Time elapsed: 8.86s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 8.90 seconds\n",
      "Fetching works for institution HR_UNIDU ROR: 05yptqp13\n",
      "Processed 200 works... (Time elapsed: 7.66s)\n",
      "Processed 400 works... (Time elapsed: 7.68s)\n",
      "Processed 600 works... (Time elapsed: 7.70s)\n",
      "Processed 800 works... (Time elapsed: 7.71s)\n",
      "Processed 1000 works... (Time elapsed: 7.73s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 7.78 seconds\n",
      "Fetching works for institution SL_EMUNI ROR: 03761pf32\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 67\n",
      "Total time taken: 1.76 seconds\n",
      "Fetching works for institution IT_UNISS ROR: 01bnjbv91\n",
      "Processed 200 works... (Time elapsed: 9.95s)\n",
      "Processed 400 works... (Time elapsed: 9.97s)\n",
      "Processed 600 works... (Time elapsed: 10.02s)\n",
      "Processed 800 works... (Time elapsed: 10.04s)\n",
      "Processed 1000 works... (Time elapsed: 10.05s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 10.14 seconds\n",
      "Fetching works for institution FR_UAG ROR: 02ryfmr77\n",
      "Processed 200 works... (Time elapsed: 13.54s)\n",
      "Processed 400 works... (Time elapsed: 13.56s)\n",
      "Processed 600 works... (Time elapsed: 13.59s)\n",
      "Processed 800 works... (Time elapsed: 13.61s)\n",
      "Processed 1000 works... (Time elapsed: 13.63s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 13.69 seconds\n",
      "Fetching works for institution PT_UAC ROR: 04276xd64\n",
      "Processed 200 works... (Time elapsed: 14.79s)\n",
      "Processed 400 works... (Time elapsed: 14.83s)\n",
      "Processed 600 works... (Time elapsed: 14.85s)\n",
      "Processed 800 works... (Time elapsed: 14.86s)\n",
      "Processed 1000 works... (Time elapsed: 14.89s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 14.96 seconds\n",
      "Fetching works for institution ES_UIB ROR: 03e10x626\n",
      "Processed 200 works... (Time elapsed: 14.28s)\n",
      "Processed 400 works... (Time elapsed: 14.31s)\n",
      "Processed 600 works... (Time elapsed: 14.33s)\n",
      "Processed 800 works... (Time elapsed: 14.35s)\n",
      "Processed 1000 works... (Time elapsed: 14.44s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 14.52 seconds\n",
      "Fetching works for institution FR_ULHN ROR: 05v509s40\n",
      "Processed 200 works... (Time elapsed: 10.79s)\n",
      "Processed 400 works... (Time elapsed: 10.81s)\n",
      "Processed 600 works... (Time elapsed: 10.83s)\n",
      "Processed 800 works... (Time elapsed: 10.85s)\n",
      "Processed 1000 works... (Time elapsed: 10.87s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 10.92 seconds\n",
      "Fetching works for institution FO_UF ROR: 05mwmd090\n",
      "Processed 200 works... (Time elapsed: 14.33s)\n",
      "Processed 400 works... (Time elapsed: 14.36s)\n",
      "Processed 600 works... (Time elapsed: 14.38s)\n",
      "Processed 800 works... (Time elapsed: 14.40s)\n",
      "Processed 1000 works... (Time elapsed: 14.42s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 14.49 seconds\n",
      "Fetching works for institution DE_HOCHSTRALSUND ROR: 04g99jx54\n",
      "Processed 200 works... (Time elapsed: 9.64s)\n",
      "Processed 400 works... (Time elapsed: 9.66s)\n",
      "Processed 600 works... (Time elapsed: 9.67s)\n",
      "Processed 800 works... (Time elapsed: 9.69s)\n",
      "Processed 1000 works... (Time elapsed: 9.70s)\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 1000\n",
      "Total time taken: 9.75 seconds\n",
      "Fetching works for institution FI_AUAS ROR: 05mknbx32\n",
      "\n",
      "Finished fetching.\n",
      "Total papers found and processed: 76\n",
      "Total time taken: 1.47 seconds\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "universities_papers = {}\n",
    "\n",
    "for key in universities_ror_id:\n",
    "    ROR_ID = universities_ror_id[key]\n",
    "    print(f\"Fetching works for institution {key} ROR: {ROR_ID}\")\n",
    "    # CHANGE n_max to None to fetch all papers\n",
    "    papers_data = fetch_papers_by_ror(ROR_ID, n_max=1000)\n",
    "    universities_papers[key] = papers_data\n",
    "\n",
    "print(len(universities_papers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9c659",
   "metadata": {},
   "source": [
    "### Total processing time\n",
    "Total processing time for all the papers at the 13 universities is **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4718d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced - Display the first few results as an example\n",
    "def display_paper_data(paper_data):\n",
    "    if paper_data:\n",
    "        print(\"\\n--- Example Paper Data (First Few) ---\")\n",
    "        for i, paper in enumerate(paper_data[0:15:5]):\n",
    "            print(f\"\\nPaper {i+1}:\")\n",
    "            print(\"-\" * 20)  # Separator for clarity\n",
    "\n",
    "            # --- Core Identifiers & Basic Metadata ---\n",
    "            print(f\"  OpenAlex ID: {paper.get('openalex_id', 'N/A')}\")\n",
    "            print(f\"  DOI: {paper.get('doi', 'N/A')}\")\n",
    "            print(f\"  Language: {paper.get('language', 'N/A')}\")\n",
    "            print(f\"  Type: {paper.get('type', 'N/A')}\")\n",
    "            print(f\"  Title: {paper.get('title', 'N/A')}\")\n",
    "            print(f\"  Publication Date: {paper.get('publication_date', 'N/A')}\")\n",
    "\n",
    "            # --- Location & Access ---\n",
    "            # Primary Location (showing key info)\n",
    "            primary_loc = paper.get('primary_location')\n",
    "            if primary_loc and isinstance(primary_loc, dict):\n",
    "                source_info = primary_loc.get('source', {})\n",
    "                source_name = source_info.get(\n",
    "                    'display_name', 'N/A') if source_info else 'N/A'\n",
    "                lp_url = primary_loc.get('landing_page_url', 'N/A')\n",
    "                print(\n",
    "                    f\"  Primary Location: Source='{source_name}', LandingPage='{lp_url}', IsOA={primary_loc.get('is_oa')}\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"  Primary Location: {primary_loc if primary_loc else 'N/A'}\")\n",
    "\n",
    "            # Open Access (showing key info)\n",
    "            oa_info = paper.get('open_access')\n",
    "            if oa_info and isinstance(oa_info, dict):\n",
    "                print(\n",
    "                    f\"  Open Access: Status='{oa_info.get('oa_status', 'N/A')}', IsOA={oa_info.get('is_oa')}, OA_URL='{oa_info.get('oa_url', 'N/A')}'\")\n",
    "            else:\n",
    "                print(f\"  Open Access: {oa_info if oa_info else 'N/A'}\")\n",
    "\n",
    "            # Best OA Location (showing key info)\n",
    "            best_oa_loc = paper.get('best_oa_location')\n",
    "            if best_oa_loc and isinstance(best_oa_loc, dict):\n",
    "                source_info = best_oa_loc.get('source', {})\n",
    "                source_name = source_info.get(\n",
    "                    'display_name', 'N/A') if source_info else 'N/A'\n",
    "                pdf_url = best_oa_loc.get('pdf_url', 'N/A')\n",
    "                print(\n",
    "                    f\"  Best OA Location: Source='{source_name}', PDF='{pdf_url}', Version='{best_oa_loc.get('version')}', License='{best_oa_loc.get('license')}'\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"  Best OA Location: {best_oa_loc if best_oa_loc else 'N/A'}\")\n",
    "\n",
    "            # --- Authorship & Affiliation ---\n",
    "            # Institutions\n",
    "            inst_list = paper.get('institutions', [])\n",
    "            print(\n",
    "                f\"  Institutions ({len(inst_list)}): {', '.join(inst_list) if inst_list else 'N/A'}\")\n",
    "\n",
    "            # Authors\n",
    "            authors_list = paper.get('authors', [])\n",
    "            print(\n",
    "                f\"  Authors ({len(authors_list)}): {', '.join(authors_list) if authors_list else 'N/A'}\")\n",
    "\n",
    "            # --- Citation Metrics & Impact ---\n",
    "            print(f\"  Cited By Count: {paper.get('cited_by_count', 'N/A')}\")\n",
    "            # Field-Weighted Citation Impact\n",
    "            print(f\"  FWCI: {paper.get('fwci', 'N/A')}\")\n",
    "            # Year/Field Normalized\n",
    "            print(\n",
    "                f\"  Citation Percentile: {paper.get('citation_normalized_percentile', 'N/A')}\")\n",
    "\n",
    "            # --- Status & Flags ---\n",
    "            print(f\"  Is Retracted: {paper.get('is_retracted', 'N/A')}\")\n",
    "            print(f\"  Is Paratext: {paper.get('is_paratext', 'N/A')}\")\n",
    "\n",
    "            # --- Content & Topics ---\n",
    "            # Abstract Preview\n",
    "            abstract_text = paper.get('abstract')\n",
    "            abstract_preview = (abstract_text[:400] + '...') if abstract_text and len(\n",
    "                abstract_text) > 400 else abstract_text\n",
    "            print(f\"  Abstract: {abstract_preview if abstract_preview else 'N/A'}\")\n",
    "\n",
    "            # Primary Topic (showing display name)\n",
    "            primary_topic_info = paper.get('primary_topic')\n",
    "            primary_topic_name = primary_topic_info.get(\n",
    "                'display_name', 'N/A') if primary_topic_info and isinstance(primary_topic_info, dict) else 'N/A'\n",
    "            print(f\"  Primary Topic: {primary_topic_name}\")\n",
    "\n",
    "            # Topics (showing count and first few display names)\n",
    "            topics_list = paper.get('topics', [])\n",
    "            topic_names = [t.get('display_name', 'N/A')\n",
    "                        for t in topics_list[:3] if isinstance(t, dict)]\n",
    "            print(\n",
    "                f\"  Topics ({len(topics_list)}): {topic_names}{'...' if len(topics_list) > 3 else ''}\")\n",
    "\n",
    "            # Keywords (showing count and first few keywords)      \n",
    "            keywords_list = paper.get('keywords', [])\n",
    "            keyword_strings = [k.get('display_name', 'N/A')\n",
    "                            for k in keywords_list[:5] if isinstance(k, dict)]\n",
    "            print(\n",
    "                f\"  Keywords ({len(keywords_list)}): {keyword_strings}{'...' if len(keywords_list) > 5 else ''}\")\n",
    "\n",
    "            # --- API & Metadata Timestamps ---\n",
    "            print(f\"  Cited By API URL: {paper.get('cited_by_api_url', 'N/A')}\")\n",
    "            print(f\"  Updated Date: {paper.get('updated_date', 'N/A')}\")\n",
    "            print(f\"  Created Date: {paper.get('created_date', 'N/A')}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo papers found matching the criteria or an error occurred before fetching any.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c32b0c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PL_ZUT', 'BG_BFU', 'GR_UOP', 'HR_UNIDU', 'SL_EMUNI', 'IT_UNISS', 'FR_UAG', 'PT_UAC', 'ES_UIB', 'FR_ULHN', 'FO_UF', 'DE_HOCHSTRALSUND', 'FI_AUAS'])\n",
      "\n",
      "--- Example Paper Data (First Few) ---\n",
      "\n",
      "Paper 1:\n",
      "--------------------\n",
      "  OpenAlex ID: https://openalex.org/W1987865306\n",
      "  DOI: https://doi.org/10.1016/s0140-6736(69)91454-8\n",
      "  Language: en\n",
      "  Type: article\n",
      "  Title: TURPENTINE AND THROMBOCYTOPENIC PURPURA\n",
      "  Publication Date: 1969-07-01\n",
      "  Primary Location: Source='The Lancet', LandingPage='https://doi.org/10.1016/s0140-6736(69)91454-8', IsOA=False\n",
      "  Open Access: Status='closed', IsOA=False, OA_URL='None'\n",
      "  Best OA Location: N/A\n",
      "  Institutions (1): Åland University of Applied Sciences\n",
      "  Authors (2): Peter Wahlberg, Dag Nyman\n",
      "  Cited By Count: 198\n",
      "  FWCI: 1.816\n",
      "  Citation Percentile: {'value': 0.992992, 'is_in_top_1_percent': True, 'is_in_top_10_percent': True}\n",
      "  Is Retracted: False\n",
      "  Is Paratext: False\n",
      "  Abstract: N/A\n",
      "  Primary Topic: Neurological and metabolic disorders\n",
      "  Topics (2): ['Neurological and metabolic disorders', 'Poisoning and overdose treatments']\n",
      "  Keywords (3): ['Thrombocytopenic purpura', 'Turpentine', 'Purpura (gastropod)']\n",
      "  Cited By API URL: https://api.openalex.org/works?filter=cites:W1987865306\n",
      "  Updated Date: 2025-04-21T18:13:22.253348\n",
      "  Created Date: 2016-06-24\n",
      "\n",
      "Paper 2:\n",
      "--------------------\n",
      "  OpenAlex ID: https://openalex.org/W2801217247\n",
      "  DOI: None\n",
      "  Language: en\n",
      "  Type: book\n",
      "  Title: Towards Openly Multilingual Policies and Practices: Assessing Minority Language Maintenance Across Europe\n",
      "  Publication Date: 2016-03-03\n",
      "  Primary Location: N/A\n",
      "  Open Access: Status='closed', IsOA=False, OA_URL='None'\n",
      "  Best OA Location: N/A\n",
      "  Institutions (3): University of Vienna, Johannes Gutenberg University Mainz, Åland University of Applied Sciences\n",
      "  Authors (4): Johanna Laakso, Anneli Sarhimaa, Sia Spiliopoulou Åkermark, Reetta Toivanen\n",
      "  Cited By Count: 30\n",
      "  FWCI: 2.665\n",
      "  Citation Percentile: {'value': 0.954691, 'is_in_top_1_percent': False, 'is_in_top_10_percent': True}\n",
      "  Is Retracted: False\n",
      "  Is Paratext: False\n",
      "  Abstract: Tables and Figures To the Reader 1. Introduction 2. European Language Vitality Barometer - A Novel Tool for Measuring the Degree of Language Maintenance at Group Level 3. Apples, Oranges, and Cranberries: Finno-Ugric Minorities in Europe and the Diversity of Diversities 4. Analysis 5. Implications and Recommendations: What Should We Do to Maintain Language Diversity in Europe? Afterword About the ...\n",
      "  Primary Topic: Linguistics, Language Diversity, and Identity\n",
      "  Topics (1): ['Linguistics, Language Diversity, and Identity']\n",
      "  Keywords (4): ['Vitality', 'Linguistic Diversity', 'Language Policy', 'Barometer']\n",
      "  Cited By API URL: https://api.openalex.org/works?filter=cites:W2801217247\n",
      "  Updated Date: 2025-04-20T20:09:02.890684\n",
      "  Created Date: 2018-05-17\n",
      "\n",
      "Paper 3:\n",
      "--------------------\n",
      "  OpenAlex ID: https://openalex.org/W1489693582\n",
      "  DOI: https://doi.org/10.1111/j.1365-2702.2010.03211.x\n",
      "  Language: en\n",
      "  Type: article\n",
      "  Title: Between being and doing – the nature of leadership of first‐line nurse managers and registered nurses\n",
      "  Publication Date: 2010-08-15\n",
      "  Primary Location: Source='Journal of Clinical Nursing', LandingPage='https://doi.org/10.1111/j.1365-2702.2010.03211.x', IsOA=False\n",
      "  Open Access: Status='closed', IsOA=False, OA_URL='None'\n",
      "  Best OA Location: N/A\n",
      "  Institutions (3): Karolinska Institutet, Marie Cederschiöld University, Åland University of Applied Sciences\n",
      "  Authors (4): Gunilla Johansson, Lars Andersson, Barbro Gustafsson, Christer Sandahl\n",
      "  Cited By Count: 28\n",
      "  FWCI: 0.707\n",
      "  Citation Percentile: {'value': 0.654485, 'is_in_top_1_percent': False, 'is_in_top_10_percent': False}\n",
      "  Is Retracted: False\n",
      "  Is Paratext: False\n",
      "  Abstract: Aims and objectives. The aim of this study was to describe first‐line nurse managers’ (F‐LNMs) and subordinate registered nurses’ (RNs) conceptions and experiences of their routine work and how leadership was exercised. Background. Extensive changes in health care organisations have had a powerful impact on leadership in nursing management. Nursing leadership, in turn, has an affect on both the qu...\n",
      "  Primary Topic: Nursing education and management\n",
      "  Topics (3): ['Nursing education and management', 'Health, psychology, and well-being', 'Interprofessional Education and Collaboration']\n",
      "  Keywords (2): ['Relevance', 'Nursing management']\n",
      "  Cited By API URL: https://api.openalex.org/works?filter=cites:W1489693582\n",
      "  Updated Date: 2025-04-16T06:06:37.568303\n",
      "  Created Date: 2016-06-24\n"
     ]
    }
   ],
   "source": [
    "print(universities_papers.keys())\n",
    "display_paper_data(universities_papers['FI_AUAS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "802d6e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of works for PL_ZUT: 13803\n",
      "Number of works for BG_BFU: 642\n",
      "Number of works for GR_UOP: 49555\n",
      "Number of works for HR_UNIDU: 2660\n",
      "Number of works for SL_EMUNI: 67\n",
      "Number of works for IT_UNISS: 25047\n",
      "Number of works for FR_UAG: 3790\n",
      "Number of works for PT_UAC: 6533\n",
      "Number of works for ES_UIB: 21872\n",
      "Number of works for FR_ULHN: 6977\n",
      "Number of works for FO_UF: 1791\n",
      "Number of works for DE_HOCHSTRALSUND: 1081\n",
      "Number of works for FI_AUAS: 76\n"
     ]
    }
   ],
   "source": [
    "for uni in universities_ror_id:\n",
    "    inst = Works().filter(institutions={\"ror\": universities_ror_id[uni]}).count()\n",
    "    print(f\"Number of works for {uni}: {inst}\")\n",
    "# for uni in universities_papers:\n",
    "    # print(f\"\\n--- {uni} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f0d79",
   "metadata": {},
   "source": [
    "## Save the data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9810c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved data for 10785 papers to university_papers_data.parquet\n"
     ]
    }
   ],
   "source": [
    "all_papers_list = []\n",
    "for university_key, papers_list in universities_papers.items():\n",
    "    if isinstance(papers_list, list):\n",
    "        for paper_doc in papers_list:\n",
    "            if isinstance(paper_doc, dict):\n",
    "                # Add the university key to each paper document\n",
    "                paper_doc_with_uni = paper_doc.copy()\n",
    "                paper_doc_with_uni['university_key'] = university_key\n",
    "                all_papers_list.append(paper_doc_with_uni)\n",
    "\n",
    "# Convert the list of dictionaries to a Pandas DataFrame\n",
    "if all_papers_list:\n",
    "    df = pd.DataFrame(all_papers_list)\n",
    "\n",
    "    # Define the output file path\n",
    "    parquet_file_path = 'university_papers_data2.parquet'\n",
    "\n",
    "    try:\n",
    "        # Save the DataFrame to a Parquet file\n",
    "        # `index=False` prevents writing the DataFrame index as a column\n",
    "        # `engine='pyarrow'` is common, 'fastparquet' is another option\n",
    "        df.to_parquet(parquet_file_path, index=False, engine='pyarrow')\n",
    "        print(\n",
    "            f\"Successfully saved data for {len(df)} papers to {parquet_file_path}\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to Parquet: {e}\")\n",
    "else:\n",
    "    print(\"No paper data was collected to save.\")\n",
    "\n",
    "\n",
    "# --- Later, to read this file to index into OpenSearch ---\n",
    "# df_loaded = pd.read_parquet(parquet_file_path, engine='pyarrow')\n",
    "# # Convert DataFrame back to list of dicts for bulk helper\n",
    "# actions_to_index = df_loaded.to_dict('records')\n",
    "# # Adapt the generate_bulk_actions function to take this list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
